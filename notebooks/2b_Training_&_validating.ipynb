{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to intialise our categorical HMM from hmm learn \n",
    "### https://hmmlearn.readthedocs.io/en/latest/api.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = hmm.CategoricalHMM(n_components = 4, n)\n",
    "hmm.CategoricalHMM(n_components = n_states, n_iter = hmm_iterations, tol = tol, params = 'ste', verbose = verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(dataframe):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Idea set them a task of creating a singular function that intialises, transforms, and trains the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_train(dataframe, states, observables, var_column, file_name, trans_probs = None, emiss_probs = None, start_probs = None, iterations = 10, hmm_iterations = 100, tol = 50, t_column = 't', bin_time = 60, test_size = 10, verbose = False):\n",
    "    \"\"\"\n",
    "\n",
    "    There must be no NaNs in the training data\n",
    "\n",
    "    Resultant hidden markov models will be saved as a .pkl file if file_name is provided\n",
    "    Final trained model probability matrices will be printed to terminal at the end of the run time\n",
    "\n",
    "    Params:\n",
    "    @states = list of sting(s), names of hidden states for the model to train to\n",
    "    @observables = list of string(s), names of the observable states for the model to train to.\n",
    "    The length must be the same number as the different categories in you movement column.\n",
    "    @trans_probs = numpy array, transtion probability matrix with shape 'len(states) x len(states)', 0's restrict the model from training any tranisitons between those states\n",
    "    @emiss_probs = numpy array, emission probability matrix with shape 'len(observables) x len(observables)', 0's same as above\n",
    "    @start_probs = numpy array, starting probability matrix with shape 'len(states) x 0', 0's same as above\n",
    "    @var_column = string, name for the column containing the variable of choice to train the model\n",
    "    @iterations = int, only used if random is True, number of loops using a different randomised starting matrices, default is 10\n",
    "    @hmm_iterations = int, argument to be passed to hmmlearn, number of iterations of parameter updating without reaching tol before it stops, default is 100\n",
    "    @tol = int, convergence threshold, EM will stop if the gain in log-likelihood is below this value, default is 50\n",
    "    @t_column = string, name for the column containing the time series data, default is 't'\n",
    "    @bin_time = int, the time in seconds the data will be binned to before the training begins, default is 60 (i.e 1 min)\n",
    "    @file_name = string, name of the .pkl file the resultant trained model will be saved to, if left as '' and random is False the model won't be saved, default is ''\n",
    "    @verbose = (bool, optional), argument for hmmlearn, whether per-iteration convergence reports are printed to terminal\n",
    "\n",
    "    returns a trained hmmlearn HMM Multinomial object\n",
    "    \"\"\"\n",
    "    \n",
    "    if file_name.endswith('.pkl') is False:\n",
    "        raise TypeError('enter a file name and type (.pkl) for the hmm object to be saved under')\n",
    "\n",
    "    n_states = len(states)\n",
    "    n_obs = len(observables)\n",
    "\n",
    "    hmm_df = self.copy(deep = True)\n",
    "\n",
    "    def bin_to_list(data, t_var, mov_var, bin):\n",
    "        \"\"\" \n",
    "        Bins the time to the given integer and creates a nested list of the movement column by id\n",
    "        \"\"\"\n",
    "        stat = 'max'\n",
    "        data = data.reset_index()\n",
    "        t_delta = data[t_column].iloc[1] - data[t_column].iloc[0]\n",
    "        if t_delta != bin:\n",
    "            data[t_var] = data[t_var].map(lambda t: bin * floor(t / bin))\n",
    "            bin_gb = data.groupby(['id', t_var]).agg(**{\n",
    "                mov_var : (var_column, stat)\n",
    "            })file_name\n",
    "            bin_gb.reset_index(level = 1, inplace = True)\n",
    "            gb = bin_gb.groupby('id')[mov_var].apply(np.array)\n",
    "        else:\n",
    "            gb = data.groupby('id')[mov_var].apply(np.array)\n",
    "        return gb\n",
    "\n",
    "    if var_column == 'beam_crosses':\n",
    "        hmm_df['active'] = np.where(hmm_df[var_column] == 0, 0, 1)\n",
    "        gb = bin_to_list(hmm_df, t_var = t_column, mov_var = var_column, bin = bin_time)\n",
    "\n",
    "    elif var_column == 'moving':\n",
    "        hmm_df[var_column] = np.where(hmm_df[var_column] == True, 1, 0)\n",
    "        gb = bin_to_list(hmm_df, t_var = t_column, mov_var = var_column, bin = bin_time)\n",
    "\n",
    "    else:\n",
    "        gb = bin_to_list(hmm_df, t_var = t_column, mov_var = var_column, bin = bin_time)\n",
    "\n",
    "    # split runs into test and train lists\n",
    "    test_train_split = round(len(gb) * (test_size/100))\n",
    "    rand_runs = np.random.permutation(gb)\n",
    "    train = rand_runs[test_train_split:]\n",
    "    test = rand_runs[:test_train_split]\n",
    "\n",
    "    len_seq_train = [len(ar) for ar in train]\n",
    "    len_seq_test = [len(ar) for ar in test]\n",
    "\n",
    "    seq_train = np.concatenate(train, 0)\n",
    "    seq_train = seq_train.reshape(-1, 1)\n",
    "    seq_test = np.concatenate(test, 0)\n",
    "    seq_test = seq_test.reshape(-1, 1)\n",
    "\n",
    "    for i in range(iterations):\n",
    "        print(f\"Iteration {i+1} of {iterations}\")\n",
    "        \n",
    "        init_params = ''\n",
    "        # h = hmm.MultinomialHMM(n_components = n_states, n_iter = hmm_iterations, tol = tol, params = 'ste', verbose = verbose)\n",
    "        h = hmm.CategoricalHMM(n_components = n_states, n_iter = hmm_iterations, tol = tol, params = 'ste', verbose = verbose)\n",
    "\n",
    "        if start_probs is None:\n",
    "            init_params += 's'\n",
    "        else:\n",
    "            s_prob = np.array([[np.random.random() if y == 'rand' else y for y in x] for x in start_probs], dtype = np.float64)\n",
    "            s_prob = np.array([[y / sum(x) for y in x] for x in t_prob], dtype = np.float64)\n",
    "            h.startprob_ = s_prob\n",
    "\n",
    "        if trans_probs is None:\n",
    "            init_params += 't'\n",
    "        else:\n",
    "            # replace 'rand' with a new random number being 0-1\n",
    "            t_prob = np.array([[np.random.random() if y == 'rand' else y for y in x] for x in trans_probs], dtype = np.float64)\n",
    "            t_prob = np.array([[y / sum(x) for y in x] for x in t_prob], dtype = np.float64)\n",
    "            h.transmat_ = t_prob\n",
    "\n",
    "        if emiss_probs is None:\n",
    "            init_params += 'e'\n",
    "        else:\n",
    "            # replace 'rand' with a new random number being 0-1\n",
    "            em_prob = np.array([[np.random.random() if y == 'rand' else y for y in x] for x in emiss_probs], dtype = np.float64)\n",
    "            em_prob = np.array([[y / sum(x) for y in x] for x in em_prob], dtype = np.float64)\n",
    "            h.emissionprob_ = em_prob\n",
    "\n",
    "        h.init_params = init_params\n",
    "        h.n_features = n_obs # number of emission states\n",
    "\n",
    "        # call the fit function on the dataset input\n",
    "        h.fit(seq_train, len_seq_train)\n",
    "\n",
    "        # Boolean output of if the number of runs convererged on set of appropriate probabilites for s, t, an e\n",
    "        print(\"True Convergence:\" + str(h.monitor_.history[-1] - h.monitor_.history[-2] < h.monitor_.tol))\n",
    "        print(\"Final log liklihood score:\" + str(h.score(seq_train, len_seq_train)))\n",
    "\n",
    "        if i == 0:\n",
    "            try:\n",
    "                h_old = pickle.load(open(file_name, \"rb\"))\n",
    "                if h.score(seq_test, len_seq_test) > h_old.score(seq_test, len_seq_test):\n",
    "                    print('New Matrix:')\n",
    "                    df_t = pd.DataFrame(h.transmat_, index = states, columns = states)\n",
    "                    print(tabulate(df_t, headers = 'keys', tablefmt = \"github\") + \"\\n\")\n",
    "                    \n",
    "                    with open(file_name, \"wb\") as file: pickle.dump(h, file)\n",
    "            except OSError as e:\n",
    "                with open(file_name, \"wb\") as file: pickle.dump(h, file)\n",
    "\n",
    "        else:\n",
    "            h_old = pickle.load(open(file_name, \"rb\"))\n",
    "            if h.score(seq_test, len_seq_test) > h_old.score(seq_test, len_seq_test):\n",
    "                print('New Matrix:')\n",
    "                df_t = pd.DataFrame(h.transmat_, index = states, columns = states)\n",
    "                print(tabulate(df_t, headers = 'keys', tablefmt = \"github\") + \"\\n\")\n",
    "                with open(file_name, \"wb\") as file: pickle.dump(h, file)\n",
    "\n",
    "        if i+1 == iterations:\n",
    "            h = pickle.load(open(file_name, \"rb\"))\n",
    "            #print tables of trained emission probabilties, not accessible as objects for the user\n",
    "            self._hmm_table(start_prob = h.startprob_, trans_prob = h.transmat_, emission_prob = h.emissionprob_, state_names = states, observable_names = observables)\n",
    "            return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _hmm_table(start_prob, trans_prob, emission_prob, state_names, observable_names):\n",
    "    \"\"\" \n",
    "    Prints a formatted table of the probabilities from a hmmlearn MultinomialHMM object\n",
    "    \"\"\"\n",
    "    df_s = pd.DataFrame(start_prob)\n",
    "    df_s = df_s.T\n",
    "    df_s.columns = state_names\n",
    "    print(\"Starting probabilty table: \")\n",
    "    print(tabulate(df_s, headers = 'keys', tablefmt = \"github\") + \"\\n\")\n",
    "    print(\"Transition probabilty table: \")\n",
    "    df_t = pd.DataFrame(trans_prob, index = state_names, columns = state_names)\n",
    "    print(tabulate(df_t, headers = 'keys', tablefmt = \"github\") + \"\\n\")\n",
    "    print(\"Emission probabilty table: \")\n",
    "    df_e = pd.DataFrame(emission_prob, index = state_names, columns = observable_names)\n",
    "    print(tabulate(df_e, headers = 'keys', tablefmt = \"github\") + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hmm_display(hmm, states, observables):\n",
    "    \"\"\"\n",
    "    Prints to screen the transion probabilities for the hidden state and observables for a given hmmlearn hmm object\n",
    "    \"\"\"\n",
    "    self._hmm_table(start_prob = hmm.startprob_, trans_prob = hmm.transmat_, emission_prob = hmm.emissionprob_, state_names = states, observable_names = observables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hmm_overtime(self, hmm, variable = 'moving', labels = None, colours = None, wrapped = False, bin = 60, func = 'max', avg_window = 30, day_length = 24, lights_off = 12, title = '', grids = False):\n",
    "    \"\"\"\n",
    "    Creates a plot of all states overlayed with y-axis shows the liklihood of being in a sleep state and the x-axis showing time in hours.\n",
    "    The plot is generated through the plotly package\n",
    "\n",
    "    Params:\n",
    "    @self = behavpy_HMM,\n",
    "    @hmm = hmmlearn.hmm.MultinomialHMM, this should be a trained HMM Learn object with the correct hidden states and emission states for your dataset\n",
    "    @variable = string, the column heading of the variable of interest. Default is \"moving\"\n",
    "    @labels = list[string], the names of the different states present in the hidden markov model. If None the labels are assumed to be ['Deep sleep', 'Light sleep', 'Quiet awake', 'Full awake']\n",
    "    @colours = list[string], the name of the colours you wish to represent the different states, must be the same length as labels. If None the colours are a default for 4 states (blue and red)\n",
    "    It accepts a specific colour or an array of numbers that are acceptable to plotly\n",
    "    @wrapped = bool, if True the plot will be limited to a 24 hour day average\n",
    "    @bin = int, the time in seconds you want to bin the movement data to, default is 60 or 1 minute\n",
    "    @func = string, when binning to the above what function should be applied to the grouped data. Default is \"max\" as is necessary for the \"moving\" variable\n",
    "    @avg_window, int, the window in minutes you want the moving average to be applied to. Default is 30 mins\n",
    "    @circadian_night, int, the hour when lights are off during the experiment. Default is ZT 12\n",
    "    @save = bool/string, if not False then save as the location and file name of the save file\n",
    "\n",
    "    returns None\n",
    "    \"\"\"\n",
    "    assert isinstance(wrapped, bool)\n",
    "\n",
    "    df = self.copy(deep = True)\n",
    "\n",
    "    labels, colours = self._check_hmm_shape(hm = hmm, lab = labels, col = colours)\n",
    "\n",
    "    states_list, time_list = self._hmm_decode(df, hmm, bin, variable, func)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    for l, t in zip(states_list, time_list):\n",
    "        tdf = hmm_pct_state(l, t, list(range(len(labels))), avg_window = int((avg_window * 60)/bin))\n",
    "        df = pd.concat([df, tdf], ignore_index = True)\n",
    "\n",
    "    if wrapped is True:\n",
    "        df['t'] = df['t'].map(lambda t: t % (60*60*day_length))\n",
    "\n",
    "    df['t'] = df['t'] / (60*60)\n",
    "    t_min = int(12 * floor(df.t.min() / 12))\n",
    "    t_max = int(12 * ceil(df.t.max() / 12))    \n",
    "    t_range = [t_min, t_max]  \n",
    "\n",
    "    fig = go.Figure()\n",
    "    self._plot_ylayout(fig, yrange = [-0.025, 1.01], t0 = 0, dtick = 0.2, ylabel = 'Probability of being in state', title = title, grid = grids)\n",
    "    self._plot_xlayout(fig, xrange = t_range, t0 = 0, dtick = day_length/4, xlabel = 'ZT (Hours)')\n",
    "\n",
    "    for c, (col, n) in enumerate(zip(colours, labels)):\n",
    "\n",
    "        column = f'state_{c}'\n",
    "\n",
    "        gb_df = df.groupby('t').agg(**{\n",
    "                    'mean' : (column, 'mean'), \n",
    "                    'SD' : (column, 'std'),\n",
    "                    'count' : (column, 'count')\n",
    "                })\n",
    "\n",
    "        gb_df['SE'] = (1.96*gb_df['SD']) / np.sqrt(gb_df['count'])\n",
    "        gb_df['y_max'] = gb_df['mean'] + gb_df['SE']\n",
    "        gb_df['y_min'] = gb_df['mean'] - gb_df['SE']\n",
    "        gb_df = gb_df.reset_index()\n",
    "\n",
    "        upper, trace, lower, _ = self._plot_line(df = gb_df, x_col = 't', name = n, marker_col = col)\n",
    "        fig.add_trace(upper)\n",
    "        fig.add_trace(trace) \n",
    "        fig.add_trace(lower)\n",
    "\n",
    "    # Light-Dark annotaion bars\n",
    "    bar_shapes, min_bar = circadian_bars(t_min, t_max, max_y = 1, day_length = day_length, lights_off = lights_off)\n",
    "    fig.update_layout(shapes=list(bar_shapes.values()))\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hmm_raw(self, hmm, variable = 'moving', colours = None, num_plots = 5, bin = 60, mago_df = None, func = 'max', show_movement = False, title = ''):\n",
    "    \"\"\" plots the raw dedoded hmm model per fly (total = num_plots) \n",
    "        If hmm is a list of hmm objects, the number of plots will equal the length of that list. Use this to compare hmm models.\n",
    "        \"\"\"\n",
    "\n",
    "    if colours is None:\n",
    "        if isinstance(hmm, list):\n",
    "            h = hmm[0]\n",
    "        else:\n",
    "            h = hmm\n",
    "        states = h.transmat_.shape[0]\n",
    "        if states == 4:\n",
    "            colours = self._colours_four\n",
    "        else:\n",
    "            raise RuntimeError(f'Your trained HMM is not 4 states, please provide the {h.transmat_.shape[0]} colours for this hmm. See doc string for more info')\n",
    "\n",
    "    colours_index = {c : col for c, col in enumerate(colours)}\n",
    "\n",
    "    if mago_df is not None:\n",
    "        assert isinstance(mago_df, behavpy) or isinstance(mago_df, behavpy_HMM), 'The mAGO dataframe is not a behavpy or behavpy_HMM class'\n",
    "\n",
    "    if isinstance(hmm, list):\n",
    "        num_plots = len(hmm)\n",
    "        rand_flies = [np.random.permutation(list(set(self.meta.index)))[0]] * num_plots\n",
    "        h_list = hmm\n",
    "        if isinstance(bin, list):\n",
    "            b_list = bin \n",
    "        else:\n",
    "            b_list = [bin] * num_plots\n",
    "    else:\n",
    "        rand_flies = np.random.permutation(list(set(self.meta.index)))[:num_plots]\n",
    "        h_list = [hmm] * num_plots\n",
    "        b_list = [bin] * num_plots\n",
    "\n",
    "    df_list = [self.xmv('id', id) for id in rand_flies]\n",
    "    decoded = [self._hmm_decode(d, h, b, variable, func) for d, h, b in zip(df_list, h_list, b_list)]\n",
    "\n",
    "    def analyse(data, df_variable):\n",
    "        states = data[0][0]\n",
    "        time = data[1][0]\n",
    "        id = df_variable.index.tolist()\n",
    "        var = df_variable[variable].tolist()\n",
    "        previous_states = np.array(states[:-1], dtype = float)\n",
    "        previous_states = np.insert(previous_states, 0, np.nan)\n",
    "        previous_var = np.array(var[:-1], dtype = float)\n",
    "        previous_var = np.insert(previous_var, 0, np.nan)\n",
    "        all_df = pd.DataFrame(data = zip(id, states, time, var, previous_states, previous_var))\n",
    "        all_df.columns = ['id','state', 't', 'var','previous_state', 'previous_var']\n",
    "        all_df.dropna(inplace = True)\n",
    "        all_df['colour'] = all_df['previous_state'].map(colours_index)\n",
    "        all_df.set_index('id', inplace = True)\n",
    "        return all_df\n",
    "\n",
    "    analysed = [analyse(i, v) for i, v in zip(decoded, df_list)]\n",
    "\n",
    "    fig = make_subplots(\n",
    "    rows= num_plots, \n",
    "    cols=1,\n",
    "    shared_xaxes=True, \n",
    "    shared_yaxes=True, \n",
    "    vertical_spacing=0.02,\n",
    "    horizontal_spacing=0.02\n",
    "    )\n",
    "\n",
    "    for c, (df, b) in enumerate(zip(analysed, b_list)):\n",
    "        id = df.first_valid_index()\n",
    "        print(f'Plotting: {id}')\n",
    "        if mago_df is not None:\n",
    "            df2 = mago_df.xmv('id', id)\n",
    "            df2 = df2[df2['has_interacted'] == 1]\n",
    "            df2['t'] = df2['interaction_t'].map(lambda t:  b * floor(t / b))\n",
    "            df2.reset_index(inplace = True)\n",
    "            df = pd.merge(df, df2, how = 'outer', on = ['id', 't'])\n",
    "            df['colour'] = np.where(df['has_responded'] == True, 'purple', df['colour'])\n",
    "            df['colour'] = np.where(df['has_responded'] == False, 'lime', df['colour'])\n",
    "            df['t'] = df['t'].map(lambda t: t / (60*60))\n",
    "        \n",
    "        else:\n",
    "            df['t'] = df['t'].map(lambda t: t / (60*60))\n",
    "\n",
    "        trace1 = go.Scatter(\n",
    "            showlegend = False,\n",
    "            y = df['previous_state'],\n",
    "            x = df['t'],\n",
    "            mode = 'markers+lines', \n",
    "            marker = dict(\n",
    "                color = df['colour'],\n",
    "                ),\n",
    "            line = dict(\n",
    "                color = 'black',\n",
    "                width = 0.5\n",
    "            )\n",
    "            )\n",
    "        fig.add_trace(trace1, row = c+1, col= 1)\n",
    "\n",
    "        if show_movement == True:\n",
    "            df['var'] = np.roll((df['var'] * 2) + 0.5, 1)\n",
    "            trace2 = go.Scatter(\n",
    "                showlegend = False,\n",
    "                y = df['var'],\n",
    "                x = df['t'],\n",
    "                mode = 'lines', \n",
    "                marker = dict(\n",
    "                    color = 'black',\n",
    "                    ),\n",
    "                line = dict(\n",
    "                    color = 'black',\n",
    "                    width = 0.75\n",
    "                )\n",
    "                )\n",
    "            fig.add_trace(trace2, row = c+1, col= 1)\n",
    "\n",
    "    y_range = [-0.2, states-0.8]\n",
    "    self._plot_ylayout(fig, yrange = y_range, t0 = 0, dtick = False, ylabel = '', title = title)\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        showgrid = False,\n",
    "        linecolor = 'black',\n",
    "        zeroline = False,\n",
    "        ticks = 'outside',\n",
    "        range = y_range, \n",
    "        tick0 = 0, \n",
    "        dtick = 1,\n",
    "        tickwidth = 2,\n",
    "        tickfont = dict(\n",
    "            size = 18\n",
    "        ),\n",
    "        linewidth = 4\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        showgrid = False,\n",
    "        color = 'black',\n",
    "        linecolor = 'black',\n",
    "        ticks = 'outside',\n",
    "        tickwidth = 2,\n",
    "        tickfont = dict(\n",
    "            size = 18\n",
    "        ),\n",
    "        linewidth = 4\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title = dict(\n",
    "            text = 'Predicted State',\n",
    "            font = dict(\n",
    "                size = 18,\n",
    "                color = 'black'\n",
    "            )\n",
    "        ),\n",
    "        row = ceil(num_plots/2),\n",
    "        col = 1\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        title = dict(\n",
    "            text = 'ZT Hours',\n",
    "            font = dict(\n",
    "                size = 18,\n",
    "                color = 'black'\n",
    "            )\n",
    "        ),\n",
    "        row = num_plots,\n",
    "        col = 1\n",
    "    )\n",
    "\n",
    "    return fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
